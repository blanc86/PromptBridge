from transformers import NllbTokenizer, AutoModelForSeq2SeqLM
import torch
from langdetect import detect

class NLLBTranslator:
    def __init__(self, model_name="facebook/nllb-200-distilled-600M"):
        self.model_name = model_name
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model = None
        self.tokenizer = None
        print(f"ğŸ§  Translator ready. Model will load lazily on first use.")

        self.lang_code_to_id = None
        self.lang_detect_map = {
            "as": "asm_Beng",
            "bn": "ben_Beng",
            "brx": "npi_Deva",
            "doi": "hin_Deva",
            "en": "eng_Latn",
            "gom": "mar_Deva",
            "gu": "guj_Gujr",
            "hi": "hin_Deva",
            "kn": "kan_Knda",
            "ks": "urd_Arab",
            "mai": "hin_Deva",
            "ml": "mal_Mlym",
            "mr": "mar_Deva",
            "ne": "npi_Deva",
            "pa": "pan_Guru",
            "sa": "san_Deva",
            "sd": "snd_Arab",
            "ta": "tam_Taml",
            "te": "tel_Telu",
            "ur": "urd_Arab"
        }

    def _load_model(self):
        if self.model is None or self.tokenizer is None:
            print(f"ğŸš€ Loading NLLB model to {self.device}...")
            self.tokenizer = NllbTokenizer.from_pretrained(self.model_name)
            self.model = AutoModelForSeq2SeqLM.from_pretrained(self.model_name).to(self.device)
            self.lang_code_to_id = self.tokenizer.convert_tokens_to_ids
            print("âœ… NLLB Model and Tokenizer loaded.")

    def detect_lang_code(self, text):
        lang = detect(text)
        return lang  # Return ISO 639-1 code like "hi", "bn", etc.

    def translate_to_english(self, text):
        self._load_model()
        iso_code = self.detect_lang_code(text)
        source_lang = self.lang_detect_map.get(iso_code, "eng_Latn")
        print(f"ğŸŒ Translating from {source_lang} â†’ eng_Latn...")
        print(f"ğŸ”¤ Input text: {text}")
        return self._translate(text, source_lang, "eng_Latn")

    def translate_from_english(self, text, target_lang_code):
        self._load_model()

        target_lang = self.lang_detect_map.get(target_lang_code)
        if not target_lang:
            raise ValueError(f"âŒ Unsupported or unknown target language code: {target_lang_code}")

        print(f"ğŸŒ Translating from eng_Latn â†’ {target_lang}...")
        print(f"ğŸ”¤ Input text: {text}")
        return self._translate(text, "eng_Latn", target_lang)

    def _translate(self, text, source_lang, target_lang):
        self.tokenizer.src_lang = source_lang
        encoded = self.tokenizer(text, return_tensors="pt").to(self.device)

        target_lang_id = self.lang_code_to_id(target_lang)
        if target_lang_id is None:
            raise ValueError(f"âŒ Invalid target language code: {target_lang}")

        generated_tokens = self.model.generate(
            **encoded,
            forced_bos_token_id=target_lang_id,
            max_length=256
        )

        translated = self.tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]
        print(f"ğŸ“ Translated text: {translated}")
        return translated

    def unload(self):
        print("ğŸ§¹ Unloading NLLB model from memory...")
        del self.model
        del self.tokenizer
        self.model = None
        self.tokenizer = None
        torch.cuda.empty_cache()
        print("âœ… Translator unloaded successfully.")

# === Shared instance ===
translator_instance = NLLBTranslator()

# === External utility functions ===
def get_translated_text(text):
    return translator_instance.translate_to_english(text)

def translate_to_user_lang(text, target_lang_code):
    return translator_instance.translate_from_english(text, target_lang_code)

def unload_translator():
    translator_instance.unload()

def get_translator_instance():
    return translator_instance


# === For testing ===
if __name__ == "__main__":
    test_cases = {
        "as": "à¦†à¦ªà§à¦¨à¦¾à§° à¦¨à¦¾à¦® à¦•à¦¿?",
        "bn": "à¦¤à§‹à¦®à¦¾à¦° à¦¨à¦¾à¦® à¦•à§€?",
        "brx": "à¤¨à¤™à¤¾à¤‡ à¤œà¥‹à¤¨à¤¾à¤¯ à¤¹à¥‹?",
        "doi": "à¤¤à¥‚à¤¹à¤¾à¤¡à¤¾ à¤¨à¤¾à¤à¤µ à¤•à¥€ à¤?",
        "en": "What is your name?",
        "gom": "à¤¤à¥à¤à¥‡ à¤¨à¤¾à¤µ à¤•à¤¿à¤¤à¥‡?",
        "gu": "àª¤àª®àª¾àª°à«àª‚ àª¨àª¾àª® àª¶à«àª‚ àª›à«‡?",
        "hi": "à¤¤à¥à¤®à¥à¤¹à¤¾à¤°à¤¾ à¤¨à¤¾à¤® à¤•à¥à¤¯à¤¾ à¤¹à¥ˆ?",
        "kn": "à²¨à²¿à²®à³à²® à²¹à³†à²¸à²°à³‡à²¨à³?",
        "ks": "ØªÙÙ‡Ù†Ø¯ Ù†Ø§Ùˆ Ú©Ù”ÛŒÛ Ú†Ú¾Ù?",
        "mai": "à¤…à¤¹à¤¾à¤à¤• à¤¨à¤¾à¤® à¤•à¥€ à¤…à¤›à¤¿?",
        "ml": "à´¨à´¿à´¨àµà´±àµ† à´ªàµ‡à´°àµ à´à´¨àµà´¤à´¾à´£àµ?",
        "mr": "à¤¤à¥à¤à¥‡ à¤¨à¤¾à¤µ à¤•à¤¾à¤¯ à¤†à¤¹à¥‡?",
        "ne": "à¤¤à¤¿à¤®à¥à¤°à¥‹ à¤¨à¤¾à¤® à¤•à¥‡ à¤¹à¥‹?",
        "pa": "à¨¤à©à¨¹à¨¾à¨¡à¨¾ à¨¨à¨¾à¨‚ à¨•à©€ à¨¹à©ˆ?",
        "sa": "à¤¤à¤µ à¤¨à¤¾à¤® à¤•à¤¿à¤®à¥ à¤…à¤¸à¥à¤¤à¤¿?",
        "sd": "ØªÙˆÚ¾Ø§Ù†Ø¬Ùˆ Ù†Ø§Ù„Ùˆ Ú‡Ø§ Ø¢Ù‡ÙŠØŸ",
        "ta": "à®‰à®™à¯à®•à®³à¯ à®ªà¯†à®¯à®°à¯ à®à®©à¯à®©?",
        "te": "à°®à±€ à°ªà±‡à°°à± à°à°®à°¿à°Ÿà°¿?",
        "ur": "Ø¢Ù¾ Ú©Ø§ Ù†Ø§Ù… Ú©ÛŒØ§ ÛÛ’ØŸ"
    }

    for lang, input_text in test_cases.items():
        print(f"\nğŸ” Testing for language code: {lang}")
        try:
            translated = translator_instance.translate_to_english(input_text)
            back_translated = translator_instance.translate_from_english(translated, lang)
            print(f"ğŸ” Round-trip: {back_translated}")
        except Exception as e:
            print(f"âŒ Error: {e}")

    translator_instance.unload()
